<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>

  <property>
      <name>fs.s3n.impl</name>
      <value>org.apache.hadoop.fs.s3native.NativeS3FileSystem</value>
      <description>Tell hadoop which class to use to access s3 URLs. This change became necessary in hadoop 2.6.0</description>
  </property>

  <property>
      <name>fs.s3.impl</name>
      <value>org.apache.hadoop.fs.s3.S3FileSystem</value>
      <description>Tell hadoop which class to use to access s3 URLs. This change became necessary in hadoop 2.6.0</description>
  </property>

  <property>
    <name>fs.s3a.impl</name>
    <value>org.apache.hadoop.fs.s3a.S3AFileSystem</value>
  </property>

  <property>
    <name>io.file.buffer.size</name>
    <value>65536</value>
  </property>

  <property>
      <name>fs.s3n.awsAccessKeyId</name>
      <value>{{aws_access_key_id}}</value>
  </property>

  <property>
      <name>fs.s3n.awsSecretAccessKey</name>
      <value>{{aws_secret_access_key}}</value>
  </property>

  <property>
    <name>fs.s3a.access.key</name>
    <value>{{aws_access_key_id}}</value>
  </property>

  <property>
    <name>fs.s3a.secret.key</name>
    <value>{{aws_secret_access_key}}</value>
  </property>

  <property>
      <name>fs.s3.maxRetries</name>
      <value>10</value>
  </property>

  <property>
    <name>fs.s3a.buffer.dir</name>
    <value>/root/spark/work,/tmp</value>
  </property>

  <property>
    <name>fs.s3a.fast.upload</name>
    <value>false</value>
    <description>Upload directly from memory instead of buffering to
    disk first. Memory usage and parallelism can be controlled as up to
    fs.s3a.multipart.size memory is consumed for each (part)upload actively
    uploading (fs.s3a.threads.max) or queueing (fs.s3a.max.total.tasks)</description>
  </property>

</configuration>
